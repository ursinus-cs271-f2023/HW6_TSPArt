{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIN00WNWevCd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "\n",
    "def read_image(path):\n",
    "    \"\"\"\n",
    "    A wrapper around matplotlib's image loader that deals with\n",
    "    images that are grayscale or which have an alpha channel\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string\n",
    "        Path to file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray(M, N, 3)\n",
    "        An RGB color image in the range [0, 1]\n",
    "    \"\"\"\n",
    "    img = plt.imread(path)\n",
    "    if np.issubdtype(img.dtype, np.integer):\n",
    "        img = np.array(img, dtype=float)/255\n",
    "    if len(img.shape) == 3:\n",
    "        if img.shape[1] > 3:\n",
    "            # Cut off alpha channel\n",
    "            img = img[:, :, 0:3]\n",
    "    if img.size == img.shape[0]*img.shape[1]:\n",
    "        # Grayscale, convert to rgb\n",
    "        img = np.concatenate((img[:, :, None], img[:, :, None], img[:, :, None]), axis=2)\n",
    "    return img\n",
    "\n",
    "def get_weights(I, thresh, p=1, canny_sigma=0):\n",
    "    \"\"\"\n",
    "    Create pre-pixel weights based on image brightness\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    I: ndarray(M, N)\n",
    "        Grayscale image\n",
    "    thresh: float\n",
    "        Amount above which to make a point 1\n",
    "    p: float\n",
    "        Contrast boost, apply weights^(1/p)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray(M, N)\n",
    "        The weights of each pixel, in the range [0, 1]\n",
    "    \"\"\"\n",
    "    weights = np.array(I)\n",
    "    if np.max(weights) > 1:\n",
    "        weights /= 255\n",
    "    weights = np.minimum(weights, thresh)\n",
    "    weights -= np.min(weights)\n",
    "    weights /= np.max(weights)\n",
    "    weights = 1-weights\n",
    "    weights = weights**(1/p)\n",
    "    if canny_sigma > 0:\n",
    "        from skimage import feature\n",
    "        edges = feature.canny(I, sigma=canny_sigma)\n",
    "        weights[edges > 0] = 1\n",
    "    return weights\n",
    "\n",
    "\n",
    "def stochastic_universal_sample(weights, target_points, jitter=0.1):\n",
    "    \"\"\"\n",
    "    Sample pixels according to a particular density using \n",
    "    stochastic universal sampling\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ndarray(M, N)\n",
    "        The weights of each pixel, in the range [0, 1]\n",
    "    target_points: int\n",
    "        The number of desired samples\n",
    "    jitter: float\n",
    "        Perform a jitter with this standard deviation of a pixel\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray(N, 2)\n",
    "        Location of point samples\n",
    "    \"\"\"\n",
    "    choices = np.zeros(target_points, dtype=int)\n",
    "    w = np.zeros(weights.size+1)\n",
    "    order = np.random.permutation(weights.size)\n",
    "    w[1::] = weights.flatten()[order]\n",
    "    w = w/np.sum(w)\n",
    "    w = np.cumsum(w)\n",
    "    p = np.random.rand() # Cumulative probability index, start off random\n",
    "    idx = 0\n",
    "    for i in range(target_points):\n",
    "        while idx < weights.size and not (p >= w[idx] and p < w[idx+1]):\n",
    "            idx += 1\n",
    "        idx = idx % weights.size\n",
    "        choices[i] = order[idx]\n",
    "        p = (p + 1/target_points) % 1\n",
    "    X = np.array(list(np.unravel_index(choices, weights.shape)), dtype=float).T\n",
    "    if jitter > 0:\n",
    "        X += jitter*np.random.randn(X.shape[0], 2)\n",
    "    return X\n",
    "\n",
    "@jit(nopython=True)\n",
    "def get_centroids(mask, N, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted centroids in a mask\n",
    "    \"\"\"\n",
    "    nums = np.zeros((N, 2))\n",
    "    denoms = np.zeros(N)\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            idx = int(mask[i, j])\n",
    "            weight = weights[i, j]\n",
    "            nums[idx, 0] += weight*i\n",
    "            nums[idx, 1] += weight*j\n",
    "            denoms[idx] += weight\n",
    "    nums = nums[denoms > 0, :]\n",
    "    denoms = denoms[denoms > 0]\n",
    "    return nums, denoms\n",
    "\n",
    "def voronoi_stipple(I, thresh, target_points, p=1, canny_sigma=0, n_iters=10, do_plot=False):\n",
    "    \"\"\"\n",
    "    An implementation of the method of [2]\n",
    "\n",
    "    [2] Adrian Secord. Weighted Voronoi Stippling\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I: ndarray(M, N, 3)\n",
    "        An RGB/RGBA or grayscale image\n",
    "    thresh: float\n",
    "        Amount above which to make a point 1\n",
    "    p: float\n",
    "        Contrast boost, apply weights^(1/p)\n",
    "    canny_sigma: float\n",
    "        If >0, use a canny edge detector with this standard deviation\n",
    "    n_iters: int\n",
    "        Number of iterations\n",
    "    do_plot: bool\n",
    "        Whether to plot each iteration\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray(N, 2)\n",
    "        An array of the stipple pattern, with x coordinates along the first\n",
    "        column and y coordinates along the second column\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import distance_transform_edt\n",
    "    import time\n",
    "    if np.max(I) > 1:\n",
    "        I = I/255\n",
    "    if len(I.shape) > 2:\n",
    "        I = 0.2125*I[:, :, 0] + 0.7154*I[:, :, 1] + 0.0721*I[:, :, 2]\n",
    "    ## Step 1: Get weights and initialize random point distributin\n",
    "    ## via rejection sampling\n",
    "    weights = get_weights(I, thresh, p, canny_sigma)\n",
    "    X = stochastic_universal_sample(weights, target_points)\n",
    "    X = np.array(np.round(X), dtype=int)\n",
    "    X[X[:, 0] >= weights.shape[0], 0] = weights.shape[0]-1\n",
    "    X[X[:, 1] >= weights.shape[1], 1] = weights.shape[1]-1\n",
    "\n",
    "    if do_plot:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "    for it in range(n_iters):\n",
    "        if do_plot:\n",
    "            plt.clf()\n",
    "            plt.scatter(X[:, 1], X[:, 0], 4)\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.xlim([0, weights.shape[1]])\n",
    "            plt.ylim([weights.shape[0], 0])\n",
    "            plt.savefig(\"Voronoi{}.png\".format(it), facecolor='white')\n",
    "        \n",
    "        mask = np.ones_like(weights)\n",
    "        X = np.array(np.round(X), dtype=int)\n",
    "        mask[X[:, 0], X[:, 1]] = 0\n",
    "\n",
    "        _, inds = distance_transform_edt(mask, return_indices=True)\n",
    "        ind2num = {}\n",
    "        for i in range(I.shape[0]):\n",
    "            for j in range(I.shape[1]):\n",
    "                coord = (inds[0, i, j], inds[1, i, j])\n",
    "                if not coord in ind2num:\n",
    "                    ind2num[coord] = len(ind2num)\n",
    "        for i in range(I.shape[0]):\n",
    "            for j in range(I.shape[1]):\n",
    "                coord = (inds[0, i, j], inds[1, i, j])\n",
    "                mask[i, j] = ind2num[coord]\n",
    "        nums, denoms = get_centroids(mask, len(ind2num), weights)\n",
    "        X = nums/denoms[:, None]\n",
    "    X[:, 0] = I.shape[0]-X[:, 0]\n",
    "    return np.fliplr(X)\n",
    "\n",
    "def density_filter(X, fac, k=1):\n",
    "    \"\"\"\n",
    "    Filter out points below a certain density\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ndarray(N, 2)\n",
    "        Point cloud\n",
    "    fac: float\n",
    "        Percentile (between 0 and 1) of points to keep, by density\n",
    "    k: int\n",
    "        How many neighbors to consider\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray(N)\n",
    "        Distance of nearest point\n",
    "    \"\"\"\n",
    "    from scipy.spatial import KDTree\n",
    "    tree = KDTree(X)\n",
    "    dd, _ = tree.query(X, k=k+1)\n",
    "    dd = np.mean(dd[:, 1::], axis=1)\n",
    "    q = np.quantile(dd, fac)\n",
    "    return X[dd < q, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "7-NT_jydey9P",
    "outputId": "374fa607-b7e6-4619-d9d1-22ecde6f2fbf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "from google.colab import drive \n",
    "drive.mount(\"/content/drive\")\n",
    "# I have the images in a directory CS271/HW6/images on my google drive\n",
    "I = read_image(\"/content/drive/MyDrive/CS271/HW6/images/penguins.png\")\n",
    "# Initial stippling\n",
    "X = voronoi_stipple(I, thresh=0.3, target_points=2000, canny_sigma=0.8)\n",
    "# Filter out lowest 4 points by density\n",
    "X = density_filter(X, (X.shape[0]-4)/X.shape[0]) \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X[:, 0], X[:, 1], 2)\n",
    "plt.savefig(\"penguins_stipple.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIT1p1iqgAzm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
